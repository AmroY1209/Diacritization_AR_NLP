{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pyarabic.araby import strip_tashkeel\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import qalsadi.lemmatizer \n",
    "import qalsadi.analex as qa\n",
    "\n",
    "from farasa.pos import FarasaPOSTagger \n",
    "from farasa.ner import FarasaNamedEntityRecognizer \n",
    "from farasa.diacratizer import FarasaDiacritizer \n",
    "from farasa.segmenter import FarasaSegmenter \n",
    "from farasa.stemmer import FarasaStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_words(words: list) -> list:\n",
    "    res = []\n",
    "    for word in words:\n",
    "        if len(word) == 1:\n",
    "            res.append('S')\n",
    "        else:\n",
    "            new_word = ''\n",
    "            new_word += 'B'\n",
    "            for i in range(1, len(word)-1):\n",
    "                new_word += 'I'\n",
    "            new_word += 'E'\n",
    "            res.append(new_word)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words_stripped = []\n",
    "\n",
    "train_data = None\n",
    "with open('./Dataset/training/train_words_stripped.txt', 'r', encoding='utf-8') as file:\n",
    "    train_data = file.readlines()\n",
    "for line in train_data:\n",
    "    train_words_stripped.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BIIE', 'BE', 'BIE', 'BIIIE', 'BIE', 'BIE', 'BIE', 'BIIIIIE', 'BIE', 'BIIE']\n",
      "['عرفة', 'ابن', 'الزركشي', 'قال', 'إلخ', 'يده', 'الأول', 'قطع', 'أو', 'قوله']\n",
      "قوله\n",
      "BIIE\n"
     ]
    }
   ],
   "source": [
    "segmented_train_words = segment_words(train_words_stripped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BIIE', 'BE', 'BIE', 'BIIIE', 'BIE', 'BIE', 'BIE', 'BIIIIIE', 'BIE', 'BIIE']\n",
      "['عرفة', 'ابن', 'الزركشي', 'قال', 'إلخ', 'يده', 'الأول', 'قطع', 'أو', 'قوله']\n",
      "قوله\n",
      "BIIE\n",
      "أو\n",
      "BE\n"
     ]
    }
   ],
   "source": [
    "print(segmented_train_words[:10])\n",
    "print(train_words_stripped[9::-1]) #reverse so English and Arabic align (only printing purpose)\n",
    "print(train_words_stripped[0])\n",
    "print(segmented_train_words[0])\n",
    "print(train_words_stripped[1])\n",
    "print(segmented_train_words[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
