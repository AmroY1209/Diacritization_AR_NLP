{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we read the data and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pyarabic.araby import strip_tashkeel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = './Dataset/train.txt'\n",
    "\n",
    "# Read Arabic text from the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    arabic_text_from_file = file.read()\n",
    "\n",
    "#print(arabic_text_from_file)\n",
    "\n",
    "#Split the text into words\n",
    "arabic_words = arabic_text_from_file.split()\n",
    "\n",
    "#remove brackets, commas, dots, numbers using regex\n",
    "arabic_words = [re.sub(r'[^\\u0600-\\u0660\\.]+', '', word) for word in arabic_words]\n",
    "stop_symbols = ['.', '،', '؟', '؛', '!', ':','...', '?.']\n",
    "arabic_words = [word for word in arabic_words if word and (len(word) > 1 or word in stop_symbols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Dataset/words.txt', 'w', encoding='utf-8') as file:\n",
    "    for word in arabic_words:\n",
    "        file.write(word + '\\n')\n",
    "\n",
    "#join the words into a string and split them according to sentences that end with a dot, question mark, or exclamation mark\n",
    "arabic_sentences = ' '.join(arabic_words)\n",
    "arabic_sentences = re.split(r'[\\.\\u061B\\u061F]', arabic_sentences) \n",
    "arabic_sentences = [sentence for sentence in arabic_sentences if sentence]\n",
    "\n",
    "with open('./Dataset/sentences.txt', 'w', encoding='utf-8') as file:\n",
    "    for sentence in arabic_sentences:\n",
    "        file.write(sentence + '\\n')\n",
    "\n",
    "# with open('./Dataset/lolTest.txt', 'w', encoding='utf-8') as file:\n",
    "#     for words in arabic_words:\n",
    "#         if words in stop_symbols:\n",
    "#             file.write(words + '\\n')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words without tashkeel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_words_without_punc = [re.sub(r'([^\\u0600-\\u0660\\.]+)|[،\\.\\u061A-\\u061F]+', '', word) for word in arabic_words]\n",
    "arabic_words_without_punc = [word for word in arabic_words_without_punc if word and (len(word) > 1 or word in stop_symbols)]\n",
    "\n",
    "with open('./Dataset/WordsWithoutTashkeel.txt', 'w', encoding='utf-8') as output_file:\n",
    "    for word in arabic_words_without_punc:\n",
    "        output_file.write(strip_tashkeel(word) + '\\n')\n",
    "\n",
    "with open('./Dataset/SentencesWithoutTashkeel.txt', 'w', encoding='utf-8') as output_file:\n",
    "    for sentence in arabic_sentences:\n",
    "        output_file.write(strip_tashkeel(sentence) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(\"بِالْحَبَشِيَّةِ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2219340\n",
      "2219340\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "print(len(arabic_words))\n",
    "for word in arabic_words:\n",
    "    new_word = word\n",
    "    if '\\u0651\\u064B' in new_word:\n",
    "        new_word = (re.sub(r'\\u0651\\u064B', 'a', new_word))\n",
    "    if '\\u0651\\u064C' in new_word:\n",
    "        new_word = (re.sub(r'\\u0651\\u064C', 'b', new_word))\n",
    "    if '\\u0651\\u064D' in new_word:\n",
    "        new_word = (re.sub(r'\\u0651\\u064D', 'c', new_word))\n",
    "    if '\\u0651\\u064E' in new_word:\n",
    "        new_word = (re.sub(r'\\u0651\\u064E', 'd', new_word))\n",
    "    if '\\u0651\\u064F' in new_word:\n",
    "        new_word = (re.sub(r'\\u0651\\u064F', 'e', new_word))\n",
    "    if '\\u0651\\u0650' in new_word:\n",
    "        new_word = (re.sub(r'\\u0651\\u0650', 'f', new_word))\n",
    "    res.append(new_word)\n",
    "print(len(res))\n",
    "\n",
    "with open('./Dataset/words_new_approach.txt', 'w', encoding='utf-8') as file:\n",
    "    for word in res:\n",
    "        file.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the words into a string and split them according to sentences that end with a dot, question mark, or exclamation mark\n",
    "arabic_sentences = ' '.join(res)\n",
    "arabic_sentences = re.split(r'[\\.\\u061B\\u061F]', arabic_sentences) \n",
    "arabic_sentences = [sentence for sentence in arabic_sentences if sentence]\n",
    "\n",
    "with open('./Dataset/sentences_new_approach.txt', 'w', encoding='utf-8') as file:\n",
    "    for sentence in arabic_sentences:\n",
    "        file.write(sentence + '\\n')\n",
    "\n",
    "# with open('./Dataset/lolTest.txt', 'w', encoding='utf-8') as file:\n",
    "#     for words in arabic_words:\n",
    "#         if words in stop_symbols:\n",
    "#             file.write(words + '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
