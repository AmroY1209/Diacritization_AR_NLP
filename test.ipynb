{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize arabic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import pyarabic.araby as araby\n",
    "import qalsadi.lemmatizer \n",
    "import qalsadi.analex as qa\n",
    "\n",
    "from farasa.pos import FarasaPOSTagger \n",
    "from farasa.ner import FarasaNamedEntityRecognizer \n",
    "from farasa.diacratizer import FarasaDiacritizer \n",
    "from farasa.segmenter import FarasaSegmenter \n",
    "from farasa.stemmer import FarasaStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have a cleaned Dataset of arabic sentences\n",
    "#we will use it to get tokens\n",
    "\n",
    "#read the dataset\n",
    "df = pd.read_csv('./Dataset/sentences.txt', encoding='utf-8')\n",
    "\n",
    "\n",
    "#tokens = nltk.word_tokenize(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " قَوْلُهُ لِعَدَمِ مَا تَتَعَلَّقُ إلَخْ أَيْ الْوَصِيَّةُ قَوْلُهُ مَا مَرَّ أَيْ قُبَيْلَ قَوْلِ الْمَتْنِ لَغَتْ وَلَوْ اقْتَصَرَ عَلَى أَوْصَيْت لَهُ بِشَاةٍ أَوْ أَعْطُوهُ شَاةً وَلَا غَنَمَ لَهُ عِنْدَ الْمَوْتِ هَلْ تَبْطُلُ الْوَصِيَّةُ أَوْ يُشْتَرَى لَهُ شَاةٌ وَيُؤْخَذُ مِنْ قَوْلِهِ الْآتِي كَمَا لَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي أَنَّهَا لَا تَبْطُلُ ، وَعِبَارَةُ الْكَنْزِ وَلَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي لَمْ يَتَعَيَّنْ غَنَمُهُ إنْ كَانَتْ انْتَهَتْ سم قَوْلُهُ فَيُعْطَى وَاحِدَةً مِنْهَا إلَخْ كَمَا لَوْ كَانَتْ مَوْجُودَةً عِنْدَ الْوَصِيَّةِ وَالْمَوْتِ ، وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ فِي الصُّورَتَيْنِ وَإِنْ تَرَاضَيَا \n"
     ]
    }
   ],
   "source": [
    "sentence = df.iloc[0][0]\n",
    "print(sentence)\n",
    "# print(araby.tokenize(sentence, morphs=araby.strip_tashkeel))\n",
    "sentence = sentence.split(\" \")\n",
    "# sentence = araby.tokenize(sentence, morphs=araby.strip_tashkeel)\n",
    "sentence = sentence[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('قول', 'noun')\n",
      "('عدم', 'noun')\n",
      "('ما', 'noun')\n",
      "('تعلق', 'verb')\n",
      "('إلخ', 'all')\n",
      "('أي', 'all')\n",
      "('وصي', 'noun')\n",
      "('قول', 'noun')\n",
      "('ما', 'noun')\n",
      "('مر', 'noun')\n",
      "('أي', 'all')\n",
      "('قبيل', 'all')\n",
      "('قول', 'noun')\n",
      "('متن', 'noun')\n",
      "('لغت', 'all')\n",
      "('ولو', 'all')\n",
      "('اقتصر', 'verb')\n",
      "('على', 'verb')\n",
      "('أوصى', 'verb')\n",
      "('له', 'all')\n",
      "('شاة', 'noun')\n",
      "('أو', 'all')\n",
      "('أعطى', 'verb')\n",
      "('شاة', 'noun')\n",
      "('ولا', 'all')\n",
      "('غنم', 'noun')\n",
      "('له', 'all')\n",
      "('عند', 'all')\n",
      "('موت', 'noun')\n",
      "('هل', 'all')\n",
      "('بطل', 'verb')\n",
      "('وصي', 'noun')\n",
      "('أو', 'all')\n",
      "('اشترى', 'verb')\n",
      "('له', 'all')\n",
      "('شاة', 'noun')\n",
      "('أخذ', 'verb')\n",
      "('مان', 'verb')\n",
      "('قول', 'noun')\n",
      "('آتي', 'noun')\n",
      "('كم', 'noun')\n",
      "('لو', 'all')\n",
      "('لم', 'all')\n",
      "('قال', 'verb')\n",
      "('مان', 'verb')\n",
      "('مال', 'noun')\n",
      "('ولا', 'all')\n",
      "('مان', 'verb')\n",
      "('غنم', 'noun')\n",
      "('أنها', 'all')\n",
      "('لا', 'noun')\n",
      "('بطل', 'verb')\n",
      "('،', 'pounct')\n",
      "('عبارة', 'noun')\n",
      "('كنز', 'noun')\n",
      "('ولو', 'all')\n",
      "('لم', 'all')\n",
      "('قال', 'verb')\n",
      "('مان', 'verb')\n",
      "('مال', 'noun')\n",
      "('ولا', 'all')\n",
      "('مان', 'verb')\n",
      "('غنم', 'noun')\n",
      "('لم', 'all')\n",
      "('تعين', 'verb')\n",
      "('غنم', 'noun')\n",
      "('إن', 'all')\n",
      "('كانت', 'all')\n",
      "('انتهى', 'verb')\n",
      "('سم', 'noun')\n",
      "('قول', 'noun')\n",
      "('أعطى', 'verb')\n",
      "('واحد', 'noun')\n",
      "('مان', 'verb')\n",
      "('إلخ', 'all')\n",
      "('كم', 'noun')\n",
      "('لو', 'all')\n",
      "('كانت', 'all')\n",
      "('موجود', 'noun')\n",
      "('عند', 'all')\n",
      "('وصي', 'noun')\n",
      "('موت', 'noun')\n",
      "('،', 'pounct')\n",
      "('ولا', 'all')\n",
      "('جاز', 'verb')\n",
      "('أن', 'all')\n",
      "('أعطى', 'verb')\n",
      "('واحد', 'noun')\n",
      "('مان', 'verb')\n",
      "('غير', 'noun')\n",
      "('غنم', 'noun')\n",
      "('في', 'all')\n",
      "('صور', 'noun')\n",
      "('وإن', 'all')\n",
      "('تراضى', 'verb')\n"
     ]
    }
   ],
   "source": [
    "lemmer = qalsadi.lemmatizer.Lemmatizer()\n",
    "\n",
    "for word in sentence:\n",
    "    print(lemmer.lemmatize(word,  return_pos=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['قَوْلُهُ', 'لِعَدَمِ', 'مَا', 'تَتَعَلَّقُ', 'إلَخْ', 'أَيْ', 'الْوَصِيَّةُ', 'قَوْلُهُ', 'مَا', 'مَرَّ', 'أَيْ', 'قُبَيْلَ', 'قَوْلِ', 'الْمَتْنِ', 'لَغَتْ', 'وَلَوْ', 'اقْتَصَرَ', 'عَلَى', 'أَوْصَيْت', 'لَهُ', 'بِشَاةٍ', 'أَوْ', 'أَعْطُوهُ', 'شَاةً', 'وَلَا', 'غَنَمَ', 'لَهُ', 'عِنْدَ', 'الْمَوْتِ', 'هَلْ', 'تَبْطُلُ', 'الْوَصِيَّةُ', 'أَوْ', 'يُشْتَرَى', 'لَهُ', 'شَاةٌ', 'وَيُؤْخَذُ', 'مِنْ', 'قَوْلِهِ', 'الْآتِي', 'كَمَا', 'لَوْ', 'لَمْ', 'يَقُلْ', 'مِنْ', 'مَالِي', 'وَلَا', 'مِنْ', 'غَنَمِي', 'أَنَّهَا', 'لَا', 'تَبْطُلُ', '،', 'وَعِبَارَةُ', 'الْكَنْزِ', 'وَلَوْ', 'لَمْ', 'يَقُلْ', 'مِنْ', 'مَالِي', 'وَلَا', 'مِنْ', 'غَنَمِي', 'لَمْ', 'يَتَعَيَّنْ', 'غَنَمُهُ', 'إنْ', 'كَانَتْ', 'انْتَهَتْ', 'سم', 'قَوْلُهُ', 'فَيُعْطَى', 'وَاحِدَةً', 'مِنْهَا', 'إلَخْ', 'كَمَا', 'لَوْ', 'كَانَتْ', 'مَوْجُودَةً', 'عِنْدَ', 'الْوَصِيَّةِ', 'وَالْمَوْتِ', '،', 'وَلَا', 'يَجُوزُ', 'أَنْ', 'يُعْطَى', 'وَاحِدَةً', 'مِنْ', 'غَيْرِ', 'غَنَمِهِ', 'فِي', 'الصُّورَتَيْنِ', 'وَإِنْ', 'تَرَاضَيَا']\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قَوْلُهُ\n",
      "{\n",
      "\t\tu'word' = u'قوله', \n",
      "\t\tu'vocalized' = u'قَوْلُهُ', \n",
      "\t\tu'unvocalized' = u'', \n",
      "\t\tu'semivocalized' = u'قَوْلهُ', \n",
      "\t\tu'tags' = u'مضاف:مرفوع:متحرك:ينون::مدخل مشكول:', \n",
      "\t\tu'affix_key' = u'--ُ-هُ|قوله', \n",
      "\t\tu'stem' = u'قول', \n",
      "\t\tu'original_tags' = u'('',)', \n",
      "\t\tu'freq' = u'406431', \n",
      "\t\tu'type' = u'Noun:مصدر:مصدر', \n",
      "\t\tu'original' = u'قَوْلٌ', \n",
      "\t\tu'tag_regular' = u'True', \n",
      "\t\tu'root' = u'قول', \n",
      "\t\tu'affix' = u'Taha', \n",
      "\t\tu'action' = u'', \n",
      "\t\tu'object_type' = u'', \n",
      "\t\tu'need' = u'', \n",
      "\t\tu'tag_type' = u'12', \n",
      "\t\tu'tag_added' = u'False', \n",
      "\t\tu'tag_initial' = u'False', \n",
      "\t\tu'tag_transparent' = u'False', \n",
      "\t\tu'tag_mamnou3' = u'False', \n",
      "\t\tu'tag_break' = u'False', \n",
      "\t\tu'tag_voice' = u'False', \n",
      "\t\tu'tag_mood' = u'False', \n",
      "\t\tu'tag_confirmed' = u'False', \n",
      "\t\tu'tag_pronoun' = u'False', \n",
      "\t\tu'tag_transitive' = u'False', \n",
      "\t\tu'tag_person' = u'4', \n",
      "\t\tu'tag_original_number' = u'مفرد', \n",
      "\t\tu'tag_original_gender' = u'مذكر', \n",
      "\t\tu'tag_number' = u'1', \n",
      "\t\tu'tag_gender' = u'1', \n",
      "\t\t}\n"
     ]
    }
   ],
   "source": [
    "analyzer = qa.Analex()\n",
    "analyzer.set_debug(False);\n",
    "word = sentence[0];\n",
    "print(word)\n",
    "\n",
    "result = analyzer.check_text(word);\n",
    "print(result[0][0])\n",
    "# for i in range(len(result)):\n",
    "#     print (\"-------------One word detailed case------\");\n",
    "#     for analyzed in  result[i]:\n",
    "#         print (\"-------------one case for word------\");\n",
    "#         print(analyzed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = FarasaSegmenter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قول+ه\n"
     ]
    }
   ],
   "source": [
    "segmented = segmenter.segment(sentence[0])\n",
    "\n",
    "print(segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger = FarasaPOSTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S/S قول/NOUN-MS +ه/PRON E/E\n"
     ]
    }
   ],
   "source": [
    "pos_tagged = pos_tagger.tag(word)\n",
    "print(pos_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['قَوْلُهُ', 'لِعَدَمِ', 'مَا', 'تَتَعَلَّقُ', 'إلَخْ', 'أَيْ', 'الْوَصِيَّةُ', 'قَوْلُهُ', 'مَا', 'مَرَّ', 'أَيْ', 'قُبَيْلَ', 'قَوْلِ', 'الْمَتْنِ', 'لَغَتْ', 'وَلَوْ', 'اقْتَصَرَ', 'عَلَى', 'أَوْصَيْت', 'لَهُ', 'بِشَاةٍ', 'أَوْ', 'أَعْطُوهُ', 'شَاةً', 'وَلَا', 'غَنَمَ', 'لَهُ', 'عِنْدَ', 'الْمَوْتِ', 'هَلْ', 'تَبْطُلُ', 'الْوَصِيَّةُ', 'أَوْ', 'يُشْتَرَى', 'لَهُ', 'شَاةٌ', 'وَيُؤْخَذُ', 'مِنْ', 'قَوْلِهِ', 'الْآتِي', 'كَمَا', 'لَوْ', 'لَمْ', 'يَقُلْ', 'مِنْ', 'مَالِي', 'وَلَا', 'مِنْ', 'غَنَمِي', 'أَنَّهَا', 'لَا', 'تَبْطُلُ', '،', 'وَعِبَارَةُ', 'الْكَنْزِ', 'وَلَوْ', 'لَمْ', 'يَقُلْ', 'مِنْ', 'مَالِي', 'وَلَا', 'مِنْ', 'غَنَمِي', 'لَمْ', 'يَتَعَيَّنْ', 'غَنَمُهُ', 'إنْ', 'كَانَتْ', 'انْتَهَتْ', 'سم', 'قَوْلُهُ', 'فَيُعْطَى', 'وَاحِدَةً', 'مِنْهَا', 'إلَخْ', 'كَمَا', 'لَوْ', 'كَانَتْ', 'مَوْجُودَةً', 'عِنْدَ', 'الْوَصِيَّةِ', 'وَالْمَوْتِ', '،', 'وَلَا', 'يَجُوزُ', 'أَنْ', 'يُعْطَى', 'وَاحِدَةً', 'مِنْ', 'غَيْرِ', 'غَنَمِهِ', 'فِي', 'الصُّورَتَيْنِ', 'وَإِنْ', 'تَرَاضَيَا']\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n",
    "\n",
    "sentence_complete = \" \".join(sentence)\n",
    "\n",
    "pos_tagged = pos_tagger.tag(sentence_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قَوْلُهُ لِعَدَمِ مَا تَتَعَلَّقُ إلَخْ أَيْ الْوَصِيَّةُ قَوْلُهُ مَا مَرَّ أَيْ قُبَيْلَ قَوْلِ الْمَتْنِ لَغَتْ وَلَوْ اقْتَصَرَ عَلَى أَوْصَيْت لَهُ بِشَاةٍ أَوْ أَعْطُوهُ شَاةً وَلَا غَنَمَ لَهُ عِنْدَ الْمَوْتِ هَلْ تَبْطُلُ الْوَصِيَّةُ أَوْ يُشْتَرَى لَهُ شَاةٌ وَيُؤْخَذُ مِنْ قَوْلِهِ الْآتِي كَمَا لَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي أَنَّهَا لَا تَبْطُلُ ، وَعِبَارَةُ الْكَنْزِ وَلَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي لَمْ يَتَعَيَّنْ غَنَمُهُ إنْ كَانَتْ انْتَهَتْ سم قَوْلُهُ فَيُعْطَى وَاحِدَةً مِنْهَا إلَخْ كَمَا لَوْ كَانَتْ مَوْجُودَةً عِنْدَ الْوَصِيَّةِ وَالْمَوْتِ ، وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ فِي الصُّورَتَيْنِ وَإِنْ تَرَاضَيَا\n"
     ]
    }
   ],
   "source": [
    "pos_tagged = pos_tagged.split(\" \")\n",
    "\n",
    "\n",
    "print(sentence_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_complete = araby.tokenize(sentence_complete, morphs=araby.strip_tashkeel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['قوله', 'لعدم', 'ما', 'تتعلق', 'إلخ', 'أي', 'الوصية', 'قوله', 'ما', 'مر', 'أي', 'قبيل', 'قول', 'المتن', 'لغت', 'ولو', 'اقتصر', 'على', 'أوصيت', 'له', 'بشاة', 'أو', 'أعطوه', 'شاة', 'ولا', 'غنم', 'له', 'عند', 'الموت', 'هل', 'تبطل', 'الوصية', 'أو', 'يشترى', 'له', 'شاة', 'ويؤخذ', 'من', 'قوله', 'الآتي', 'كما', 'لو', 'لم', 'يقل', 'من', 'مالي', 'ولا', 'من', 'غنمي', 'أنها', 'لا', 'تبطل', '،', 'وعبارة', 'الكنز', 'ولو', 'لم', 'يقل', 'من', 'مالي', 'ولا', 'من', 'غنمي', 'لم', 'يتعين', 'غنمه', 'إن', 'كانت', 'انتهت', 'سم', 'قوله', 'فيعطى', 'واحدة', 'منها', 'إلخ', 'كما', 'لو', 'كانت', 'موجودة', 'عند', 'الوصية', 'والموت', '،', 'ولا', 'يجوز', 'أن', 'يعطى', 'واحدة', 'من', 'غير', 'غنمه', 'في', 'الصورتين', 'وإن', 'تراضيا']\n"
     ]
    }
   ],
   "source": [
    "print(sentence_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S/S قول/NOUN-MS +ه/PRON E/E', 'S/S ل+/PREP عدم/NOUN-MS E/E', 'S/S ما/PART E/E', 'S/S تتعلق/V E/E', 'S/S إلخ/ABBREV E/E', 'S/S أي/PART E/E', 'S/S ال+ وصي +ة/DET+NOUN+NSUFF-FS E/E', 'S/S قول/NOUN-MS +ه/PRON E/E', 'S/S ما/PART E/E', 'S/S مر/V E/E', 'S/S أي/PART E/E', 'S/S قبيل/NOUN-MS E/E', 'S/S قول/NOUN-MS E/E', 'S/S ال+ متن/DET+NOUN-MS E/E', 'S/S ل+/PREP غت/NOUN-MS E/E', 'S/S و+/CONJ لو/PART E/E', 'S/S اقتصر/V E/E', 'S/S على/PREP E/E', 'S/S أوصي +ت/V+PRON E/E', 'S/S ل+/PREP +ه/PRON E/E', 'S/S ب+/PREP شا +ة/NOUN+NSUFF-FS E/E', 'S/S أو/CONJ E/E', 'S/S أعطو/V +ه/PRON E/E', 'S/S شا +ة/NOUN+NSUFF-FS E/E', 'S/S و+/CONJ لا/PART E/E', 'S/S غنم/V E/E', 'S/S ل+/PREP +ه/PRON E/E', 'S/S عند/NOUN-MS E/E', 'S/S ال+ موت/DET+NOUN-MS E/E', 'S/S هل/PART E/E', 'S/S تبطل/V E/E', 'S/S ال+ وصي +ة/DET+NOUN+NSUFF-FS E/E', 'S/S أو/CONJ E/E', 'S/S يشترى/V E/E', 'S/S ل+/PREP +ه/PRON E/E', 'S/S شا +ة/NOUN+NSUFF-FS E/E', 'S/S و+/CONJ يؤخذ/V E/E', 'S/S من/PREP E/E', 'S/S قول/NOUN-MS +ه/PRON E/E', 'S/S ال+ آتي/DET+ADJ-MS E/E', 'S/S كما/PREP+PART E/E', 'S/S لو/PART E/E', 'S/S لم/PART E/E', 'S/S يقل/V E/E', 'S/S من/PREP E/E', 'S/S مالي/ADJ-MS E/E', 'S/S و+/CONJ لا/PART E/E', 'S/S من/PREP E/E', 'S/S غنم/NOUN-MS +ي/PRON E/E', 'S/S أن/PART +ها/PRON E/E', 'S/S لا/PART E/E', 'S/S تبطل/V E/E', 'S/S ،/PUNC E/E', 'S/S و+/CONJ عبار +ة/NOUN+NSUFF-FS E/E', 'S/S ال+ كنز/DET+NOUN-MS E/E', 'S/S و+/CONJ لو/PART E/E', 'S/S لم/PART E/E', 'S/S يقل/V E/E', 'S/S من/PREP E/E', 'S/S مالي/ADJ-MS E/E', 'S/S و+/CONJ لا/PART E/E', 'S/S من/PREP E/E', 'S/S غنم/NOUN-MS +ي/PRON E/E', 'S/S لم/PART E/E', 'S/S يتعين/V E/E', 'S/S غنم/V +ه/PRON E/E', 'S/S إن/PART E/E', 'S/S كان +ت/V+PRON E/E', 'S/S انته +ت/V+PRON E/E', 'S/S سم/ABBREV E/E', 'S/S قول/NOUN-MS +ه/PRON E/E', 'S/S ف+/CONJ يعطى/V E/E', 'S/S واحد +ة/NOUN+NSUFF-FP E/E', 'S/S من/PREP +ها/PRON E/E', 'S/S إلخ/ABBREV E/E', 'S/S كما/PREP+PART E/E', 'S/S لو/PART E/E', 'S/S كان +ت/V+PRON E/E', 'S/S موجود +ة/ADJ+NSUFF-FP E/E', 'S/S عند/NOUN-MS E/E', 'S/S ال+ وصي +ة/DET+NOUN+NSUFF-FS E/E', 'S/S و+/CONJ ال+ موت/DET+NOUN-MS E/E', 'S/S ،/PUNC E/E', 'S/S و+/CONJ لا/PART E/E', 'S/S يجوز/V E/E', 'S/S أن/PART E/E', 'S/S يعطى/V E/E', 'S/S واحد +ة/NOUN+NSUFF-FP E/E', 'S/S من/PREP E/E', 'S/S غير/PART E/E', 'S/S غنم/V +ه/PRON E/E', 'S/S في/PREP E/E', 'S/S ال+ صور +ت +ين/DET+NOUN+NSUFF+NSUFF-FP E/E', 'S/S و+/CONJ إن/PART E/E', 'S/S تراضي/NOUN-MS +ا/CASE E/E']\n"
     ]
    }
   ],
   "source": [
    "pos_list = []\n",
    "for word in sentence_complete:\n",
    "    pos_tagged = pos_tagger.tag(word)\n",
    "    pos_list.append(pos_tagged)\n",
    "\n",
    "print(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
